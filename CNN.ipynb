{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa01c3db-1b78-49a3-974d-885ae790f575",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f8ff7d-99ac-49fd-9d81-000ef4c812fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob as gb\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c804bdf0-d79c-4a7c-9e8f-d7235b849aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = r\"D:\\Project\\PG Project\\Data\\Image Data\\seg_train\"\n",
    "\n",
    "test_dataset_path = r\"D:\\Project\\PG Project\\Data\\Image Data\\seg_test\"\n",
    "\n",
    "predict_dataset_path = r\"D:\\Project\\PG Project\\Data\\Image Data\\seg_pred\\seg_pred\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5caa6e-1d6d-4c42-a85d-fe2f5b1448b8",
   "metadata": {},
   "source": [
    "### Checking data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c5ee87-6c40-4d22-b863-556360608199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data, found 2190 images in folder buildings\n",
      "For training data, found 2263 images in folder forest\n",
      "For training data, found 2387 images in folder glacier\n",
      "For training data, found 2495 images in folder mountain\n",
      "For training data, found 2270 images in folder sea\n",
      "For training data, found 2381 images in folder street\n",
      "\n",
      "For testing data, found 437 images in folder buildings\n",
      "For testing data, found 473 images in folder forest\n",
      "For testing data, found 549 images in folder glacier\n",
      "For testing data, found 523 images in folder mountain\n",
      "For testing data, found 510 images in folder sea\n",
      "For testing data, found 501 images in folder street\n",
      "\n",
      "For predicting data, found 7288 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset_checking_path = os.path.join(train_dataset_path, 'seg_train')\n",
    "\n",
    "for folder in os.listdir(train_dataset_checking_path):\n",
    "    folder_path = os.path.join(train_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    print(f\"For training data, found {len(files)} images in folder {folder}\")\n",
    "print()\n",
    "\n",
    "test_dataset_checking_path = os.path.join(test_dataset_path, 'seg_test')\n",
    "\n",
    "for folder in os.listdir(test_dataset_checking_path):\n",
    "    folder_path = os.path.join(test_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    print(f\"For testing data, found {len(files)} images in folder {folder}\")\n",
    "print()\n",
    "\n",
    "files = gb.glob(os.path.join(predict_dataset_path, '*.jpg'))\n",
    "print(f\"For predicting data, found {len(files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4682e3b0-c7f3-4463-b134-021affb9a3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image size\t Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)    13986\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = []\n",
    "for folder in os.listdir(train_dataset_checking_path):\n",
    "    folder_path = os.path.join(train_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    for file in files: \n",
    "        image = plt.imread(file)\n",
    "        size.append(image.shape)\n",
    "print(' Image size\\t Count')\n",
    "pd.Series(size).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ceeb77-a700-4360-bc00-5f381b64e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image size\t Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)    2993\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = []\n",
    "for folder in os.listdir(test_dataset_checking_path):\n",
    "    folder_path = os.path.join(test_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    for file in files: \n",
    "        image = plt.imread(file)\n",
    "        size.append(image.shape)\n",
    "print(' Image size\\t Count')\n",
    "pd.Series(size).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a839029-a310-4016-83a0-44c42e5eb326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image size\t Count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)    7288\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = []\n",
    "files = gb.glob(os.path.join(predict_dataset_path, '*.jpg'))\n",
    "for file in files: \n",
    "    image = plt.imread(file)\n",
    "    size.append(image.shape)\n",
    "print(' Image size\\t Count')\n",
    "pd.Series(size).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a6446-eee3-4066-a9dc-f1efe51c510c",
   "metadata": {},
   "source": [
    "### Retain (150,150,3)-sized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6c84f2-d512-420c-91b9-e03d0dbd7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving 0 train_images to D:\\项目\\Comp702\\Data\\Image Data\\Removed_train_images\n",
      "moving 0 test_images to D:\\项目\\Comp702\\Data\\Image Data\\Removed_train_images\n",
      "moving 0 predict_images to D:\\项目\\Comp702\\Data\\Image Data\\Removed_train_images\n"
     ]
    }
   ],
   "source": [
    "Removed_image_dir = os.path.join(r'D:\\项目\\Comp702\\Data\\Image Data', 'Removed_train_images')\n",
    "os.makedirs(Removed_image_dir, exist_ok=True)\n",
    "\n",
    "moved_count1 = 0\n",
    "moved_count2 = 0\n",
    "moved_count3 = 0\n",
    "\n",
    "for folder in os.listdir(train_dataset_checking_path):\n",
    "    folder_path = os.path.join(train_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    for file in files:\n",
    "        with Image.open(file) as img:\n",
    "            img = img.convert('RGB')  # 转换为 RGB\n",
    "            if img.size != (150, 150):\n",
    "                # 构建新文件名，包含类别前缀\n",
    "                new_name = f\"{folder}_{os.path.basename(file)}\"\n",
    "                shutil.move(file, os.path.join(Removed_image_dir, new_name))\n",
    "                moved_count1 += 1\n",
    "\n",
    "\n",
    "\n",
    "for folder in os.listdir(test_dataset_checking_path):\n",
    "    folder_path = os.path.join(test_dataset_checking_path, folder)\n",
    "    files = gb.glob(os.path.join(folder_path, '*.jpg'))\n",
    "    for file in files:\n",
    "        with Image.open(file) as img:\n",
    "            img = img.convert('RGB')  # 转换为 RGB\n",
    "            if img.size != (150, 150):\n",
    "                # 构建新文件名，包含类别前缀\n",
    "                new_name = f\"{folder}_{os.path.basename(file)}\"\n",
    "                shutil.move(file, os.path.join(Removed_image_dir, new_name))\n",
    "                moved_count2 += 1\n",
    "\n",
    "\n",
    "files = gb.glob(os.path.join(predict_dataset_path, '*.jpg'))\n",
    "for file in files:\n",
    "        with Image.open(file) as img:\n",
    "            img = img.convert('RGB')  # 转换为 RGB\n",
    "            if img.size != (150, 150):\n",
    "                # 构建新文件名，包含类别前缀\n",
    "                new_name = f\"{folder}_{os.path.basename(file)}\"\n",
    "                shutil.move(file, os.path.join(Removed_image_dir, new_name))\n",
    "                moved_count3 += 1\n",
    "\n",
    "print(f\"moving {moved_count1} train_images to {Removed_image_dir}\")\n",
    "print(f\"moving {moved_count2} test_images to {Removed_image_dir}\")\n",
    "print(f\"moving {moved_count3} predict_images to {Removed_image_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27e0bb-d4a7-47ef-a986-094365feb97d",
   "metadata": {},
   "source": [
    "### Label Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca320a1d-74b5-48a1-9d02-4eec2673d82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n"
     ]
    }
   ],
   "source": [
    "class_names = ['buildings','forest','glacier','mountain','sea','street']\n",
    "class_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "print(class_labels)\n",
    "\n",
    "number_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26d95d-a2a7-4853-a18d-937471e4fcdb",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6641073-33de-461c-8cab-fd04e3b514ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"D:\\Project\\PG Project\\Data\\Image Data\\seg_train\\seg_train\"\n",
    "test_dir = r\"D:\\Project\\PG Project\\Data\\Image Data\\seg_test\\seg_test\"\n",
    "\n",
    "def load_dataset():\n",
    "    # create list of datasets\n",
    "    datasets = [train_dir, test_dir]\n",
    "    output = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images1 = []\n",
    "        labels1 = []\n",
    "        print(f\"loading {dataset}\")\n",
    "        \n",
    "        for folder in os.listdir(dataset):\n",
    "            # assign labels to each folder images\n",
    "            label = class_labels[folder]\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset,folder))):\n",
    "                image_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                # read the image files stored in image_path\n",
    "                image_file = cv2.imread(image_path)\n",
    "                image_file = cv2.cvtColor(image_file, cv2.COLOR_BGR2RGB)\n",
    "                image_file = cv2.resize(image_file, IMAGE_SIZE)\n",
    "                \n",
    "                images1.append(image_file)\n",
    "                labels1.append(label)\n",
    "                \n",
    "        # convert the images and labels list to numpy array\n",
    "        images1 = np.array(images1, dtype = 'float32')\n",
    "        labels1 = np.array(labels1, dtype = 'int32')\n",
    "        \n",
    "        output.append((images1, labels1))\n",
    "        print(\"Images file have been loaded\")\n",
    "                \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706a0eb4-74a9-4bc8-94eb-0876db69f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading D:\\Project\\PG Project\\Data\\Image Data\\seg_train\\seg_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2190/2190 [00:01<00:00, 1359.83it/s]\n",
      "100%|██████████| 2263/2263 [00:01<00:00, 1235.62it/s]\n",
      "100%|██████████| 2387/2387 [00:01<00:00, 1323.90it/s]\n",
      "100%|██████████| 2495/2495 [00:01<00:00, 1468.00it/s]\n",
      "100%|██████████| 2270/2270 [00:01<00:00, 1278.99it/s]\n",
      "100%|██████████| 2381/2381 [00:01<00:00, 1224.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images file have been loaded\n",
      "loading D:\\Project\\PG Project\\Data\\Image Data\\seg_test\\seg_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [00:00<00:00, 1666.38it/s]\n",
      "100%|██████████| 473/473 [00:00<00:00, 1493.82it/s]\n",
      "100%|██████████| 549/549 [00:00<00:00, 1739.00it/s]\n",
      "100%|██████████| 523/523 [00:00<00:00, 1672.58it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 1676.51it/s]\n",
      "100%|██████████| 501/501 [00:00<00:00, 1555.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images file have been loaded\n"
     ]
    }
   ],
   "source": [
    "((train_images, train_labels), (test_images, test_labels)) = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1084766b-44f9-4a98-87d5-e774d0d398e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size 13986 13986\n",
      "test dataset size 2993 2993\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset size\",len(train_images), len(train_labels))\n",
    "print(\"test dataset size\",len(test_images), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f9239-5f98-4589-8aeb-71c92655f22a",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080e0079-5dff-45fd-910a-e4c9b8c6d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c0c3f-24ee-4ace-b7d3-8e14dce97761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
